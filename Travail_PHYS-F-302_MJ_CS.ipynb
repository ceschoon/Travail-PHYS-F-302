{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>PHYS-F-302</center></h1>\n",
    "<h1><center>Partie numérique</center></h1>\n",
    "<h2><center>Cédric SCHOONEN, Maxime JAMOTTE</center></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans ce notebook, nous résolverons le problème donné à l'adresse https://github.com/bknaepen/MATHF314_2017/ dans le dossier Stokes. Le problème consiste à résoudre l'équation $\\Delta^2\\psi=0$ par la méthode du \"gradient conjugé\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Justification physique des conditions aux bords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commençons par donner une justification physique au choix des conditions aux bords utilisé dans l'énoncé.\n",
    "\n",
    "Traitons d'abord les conditions placées sur les dérivées de la stream function $\\psi$. Celles-ci sont listées ci-dessous:\n",
    "\n",
    "| $\\partial_x \\psi = 0$ | $\\partial_y \\psi = 1$ | $\\partial_x \\psi = 0$ | $\\partial_y \\psi = 0$ |\n",
    "|-----------------------|-----------------------|-----------------------|-----------------------|\n",
    "| bord immobile // y    | bord mobile // x      | bord immobile // y    | bord immobile // x    |\n",
    "\n",
    "Notre argument pour justifier ces conditions est que le fluide ne \"glisse\" pas sur les parois de la cavité, i.e. La composante tangentielle à la paroi de la vitesse relative entre le fluide et le bord en question est nulle près du bord. Cet argument s'appuie sur l'existence de forces intermoléculaires entre les molécules de fluide et de la paroi, d'aspérités sur la paroi ainsi que sur la nature fluidique du fluide concerné. La logique est qu'à la fois les forces intermoléculaires et les aspérités du bord vont avoir tendance à retenir les molécules de fluide proches de la paroi immobiles par rapport à cette dernière. La fluidité du fluide va rendre cette immobilisation possible car les molécules de fluide plus éloignées de la paroi vont simplement \"rouler\" sur les molécules plus proches sans les emporter totalement avec elles. En pratique, cela implique que la vitesse tangentielle du fluide au plus proche des bords est la même que la vitesse de la paroi. Par example, la vitesse tangentielle près du bord mobile de vitesse $1$ sera $u=1$. Sachant que $ u = \\partial_y\\psi$ et $v = -\\partial_x\\psi$, nous avons bien dans notre cas $\\partial_y\\psi = u = 1$.\n",
    "\n",
    "La condition sur $\\psi$, fixée à $0$ sur tout le périmètre de la cavité, se justifie quant à elle par un autre argument. Cet argument repose sur l'imperméabilé de la paroi. En effet, si les molécules ne peuvent traverser les bords, il est nécessaire que leur vitesse normale s'annule au plus près de ces bords. Se rappelant de la relation entre $u,v$ et les dérivées de $\\psi$, nous voyons que cela implique que la dérivée de $\\psi$ dans la direction tangentielle à un bord est nulle sur ce bord. Par la continuité de $\\psi$ dans la cavité, nous avons donc que $\\psi$ prend la même valeur sur tout le périmètre de cette cavité. Comme seules les dérivées de $\\psi$ ont un sens physique, nous pouvons librement choisir de fixer cette valeur à $0$.\n",
    "\n",
    "Nous avons donc vérifié que les conditions aux bords qui ont été choisies décrivent bien la situation physique attendue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discrétisation de l'opérateur bilaplacien\n",
    "\n",
    "Le bilaplacien de $\\psi$ à discrétiser s'écrit comme $\\Delta^2\\psi = \\partial_{xxxx}\\psi + 2\\partial_{xxyy}\\psi + \\partial_{yyyy}\\psi$ en supposant $\\psi$ suffisamment régulière.\n",
    "\n",
    "Nous pouvons exprimer les dérivées d'ordre 2 et 4 dans les directions $x,y$ de la façon suivante:\n",
    "\n",
    "$$ \\partial_{xx}\\psi_{i,j} = \\frac{ \\psi_{i,j+1} -2 \\psi_{i,j} + \\psi_{i,j-1} }{ (dx)^2 } + \\cal O((dx)^2) $$\n",
    "\n",
    "$$ \\partial_{yy}\\psi_{i,j} = \\frac{ \\psi_{i-1,j} -2 \\psi_{i,j} + \\psi_{i+1,j} }{ (dy)^2 } + \\cal O((dy)^2) $$\n",
    "\n",
    "$$ \\partial_{xxxx}\\psi_{i,j} = \\frac{ \\psi_{i,j+2} -4 \\psi_{i,j+1} +6 \\psi_{i,j} -4\\psi_{i,j-1} + \\psi_{i,j-2} }{ (dx)^4 } + \\cal O((dx)^2) $$\n",
    "\n",
    "$$ \\partial_{yyyy}\\psi_{i,j} = \\frac{ \\psi_{i-2,j} -4 \\psi_{i-1,j} +6 \\psi_{i,j} -4\\psi_{i+1,j} + \\psi_{i+2,j} }{ (dy)^4 } + \\cal O((dy)^2) $$\n",
    "\n",
    "Les discrétisations des dérivées secondes sont utiles pour trouver celle de la dérivée croisée $\\partial_{xxyy}\\psi$:\n",
    "\n",
    "$$ \\partial_{xxyy}\\psi_{i,j} = \\frac{ \\partial_{yy}\\psi_{i,j+1} -2 \\partial_{yy}\\psi_{i,j} + \\partial_{yy}\\psi_{i,j-1} }{ (dx)^2 } + \\cal O((dx)^2) $$\n",
    "\n",
    "En remplaçant, cela donne\n",
    "\n",
    "$$ \\partial_{xxyy}\\psi_{i,j} = \\frac{ \\frac{\\psi_{i-1,j+1} -2 \\psi_{i,j+1} + \\psi_{i+1,j+1}}{(dy)^2} + \\cal O((dy)^2)\n",
    "                                    -2\\frac{\\psi_{i-1,j  } -2 \\psi_{i,j  } + \\psi_{i+1,j  }}{(dy)^2} + \\cal O((dy)^2)\n",
    "                                    + \\frac{\\psi_{i-1,j-1} -2 \\psi_{i,j-1} + \\psi_{i+1,j-1}}{(dy)^2} + \\cal O((dy)^2)\n",
    "                                    }{(dx)^2} + \\cal O((dx)^2) $$\n",
    "$$ \\partial_{xxyy}\\psi_{i,j} = \\frac{\\psi_{i-1,j+1}  -2 \\psi_{i,j+1} +  \\psi_{i+1,j+1}\n",
    "                                     -2 \\psi_{i-1,j} +4 \\psi_{i-1,j} -2 \\psi_{i+1,j}\n",
    "                                     \\psi_{i-1,j-1}  -2 \\psi_{i,j-1} +  \\psi_{i+1,j-1}\n",
    "                                     }{(dx)^2(dy)^2} + \\cal O((dx)^2) + \\cal O((dy)^2) + \\cal O\\left(\\frac{(dx)^4}{(dy)^2}\\right) $$       \n",
    "                                     \n",
    "Les coefficients sont plus facilement visualisés dans le tableau suivant:\n",
    "\n",
    "|     || j-1 |  j  | j+1 |\n",
    "|-----||-----|-----|-----|\n",
    "| i-1 ||  1  | -2  |  1  |\n",
    "|  i  || -2  |  4  | -2  |\n",
    "| i+1 ||  1  | -2  |  1  |\n",
    "\n",
    "Notons qu'il est laborieux de montrer que les termes en $\\cal O((dx)^2)$ du numérateur se simplifient pour donner une erreur en $\\cal O\\left(\\frac{(dx)^4}{(dy)^2}\\right)$. De plus, cette preuve nous semble dénuée d'intérêt pour le sujet c'est pourquoi nous ne l'écrirons pas ici. Cependant, l'ayant faite, nous sommes interrogeables sur le sujet.\n",
    "\n",
    "Les coefficients pour le bilaplacien se résument donc *dans le cas où $dx$ = $dy$* par:\n",
    "\n",
    "|     || j-2 | j-1 |  j  | j+1 | j+2 |\n",
    "|-----||-----|-----|-----|-----|-----|\n",
    "| i-2 ||     |     |  1  |     |     |\n",
    "| i-1 ||     |  2  | -8  |  2  |     |\n",
    "|  i  ||  1  | -8  | 20  | -8  |  1  |\n",
    "| i+1 ||     |  2  | -8  |  2  |     |\n",
    "| i+2 ||     |     |  1  |     |     |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Discrétisation des conditions aux bords\n",
    "\n",
    "Nous avons deux conditions aux bords à discrétiser. La première est $\\psi = 0$, que nous implémentons de manière évidente et correcte à tous les ordres comme \n",
    "\n",
    "$$\\psi_{i,0} = \\psi_{i,N-1} = \\psi_{0,j} = \\psi_{N-1,j} = 0 \\quad \\forall i,j=0,...,N-1$$\n",
    "\n",
    "La deuxième condition aux bords est portée sur les dérivées de $\\psi$ et prend des expressions différentes suivant le bord en question. La condition sur le bord situé en $x=0$ est $\\partial_x\\psi = 0$. Nous la discrétisons en considérant une approximation à l'ordre 1 de type forward de la dérivée en $x=0$:\n",
    "\n",
    "$$ 0 = \\partial_x\\psi_{i,0} = \\frac{-\\frac 32\\psi_{i,0} + 2\\psi_{i,1} -\\frac 12\\psi_{i,2}}{dx} + \\mathcal O((dx)^2) $$\n",
    "$$ \\psi_{i,1} = \\frac 34 \\psi_{i,0} + \\frac 14 \\psi_{i,2} + \\mathcal O((dx)^3) = \\frac 14 \\psi_{i,2} + \\mathcal O((dx)^3) $$\n",
    "\n",
    "Il est facile de voir que ce raisonnement se généralise à tous les côtés. Nous détaillons encore le côté supérieur pour lequel la condition est légèrement différente.\n",
    "\n",
    "$$ 1 = \\partial_y\\psi_{N-1,j} = \\frac{\\frac 32\\psi_{N-1,j} - 2\\psi_{N-2,j} +\\frac 12 \\psi_{N-3,j}}{dy} + \\mathcal O((dy)^2) $$\n",
    "$$ \\psi_{N-2,j} = -\\frac 12 dy + \\frac 34 \\psi_{N-1,j} + \\frac 14 \\psi_{N-3,j} + \\mathcal O((dx)^3) = -\\frac 12 dy + \\frac 14 \\psi_{N-3,j} + \\mathcal O((dx)^3) $$\n",
    "\n",
    "Nos conditions sur les dérivées se résument donc de la façon suivante:\n",
    "\n",
    "$$ \\psi_{i,1} = \\frac 14 \\psi_{i,2} + \\cal O((dx)^3) $$\n",
    "$$ \\psi_{i,N-2}        = \\frac 14 \\psi_{i,N-3} + \\cal O((dx)^3) $$\n",
    "$$ \\psi_{1,j}        =  \\frac 14 \\psi_{2,j} + \\cal O((dy)^3) $$\n",
    "$$ \\qquad \\ \\  \\psi_{N-2,j} = -\\frac 12 dy + \\frac 14 \\psi_{N-3,j} + \\mathcal O((dy)^3) $$\n",
    "\n",
    "Remarquons que l'imposition des conditions aux bords est incohérentes pour les 2 points $(N-2,1)$ et $(N-2,N-2)$ situés près des coins. En effet, ceux-ci se retrouvent deux fois dans les formules ci-dessus et se voient imposées deux valeurs différentes. Ceci amène un choix arbitraire dans notre code concernant la valeur à utiliser. Cependant, ceci n'est pas un problème physique car dans la limite $N\\rightarrow \\infty$, $dy\\rightarrow 0$ et les deux valeurs coïncident. Il nous a donc semblé plus naturel d'imposer directement la valeur la plus proche de  $0$, c'est à dire la condition donnée pour le bord parallèle à l'axe $y$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implémentation de la méthode du gradient conjugé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from matplotlib import pyplot\n",
    "import numpy\n",
    "%matplotlib inline\n",
    "from matplotlib import rcParams\n",
    "rcParams['font.family'] = 'serif'\n",
    "rcParams['font.size'] = 16\n",
    "from matplotlib import pyplot, cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous importons des fonctions prédéfinies dans le mooc pour la méthode du gradient conjugé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import Conjugate_Gradient as cg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous implémentons maintenant le bilaplacien discrétisé plus haut. Comme les conditions aux bords fixent les valeurs pour les deux rangées de points extérieurs, nous ne calculons le bilaplacien que dans un carré centré de taille $(N-4)\\times (N-4)$. Les conditions aux bords sont implémentées dans l'opérateur lui-même, via le champ $p$ à partir duquel il est calculé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def impose_bc(p0,dy):\n",
    "    \n",
    "    p = p0.copy()\n",
    "    \n",
    "    p[:,0]  = 0\n",
    "    p[:,-1] = 0\n",
    "    p[0,:]  = 0\n",
    "    p[-1,:] = 0\n",
    "    \n",
    "    p[2:-2,1]  =       0 + 1/4*p0[2:-2,2]\n",
    "    p[2:-2,-2] =       0 + 1/4*p0[2:-2,-3]\n",
    "    p[1,2:-2]  =       0 + 1/4*p0[2,2:-2]    \n",
    "    p[-2,2:-2] = -1/2*dy + 1/4*p0[-3,2:-2] \n",
    "    \n",
    "    p[1,1] = p0[2,2]/16\n",
    "    p[1,-2] = p0[2,-3]/16\n",
    "    p[-2,1] = p0[-3,2]/16\n",
    "    p[-2,-2] = p0[-3,-3]/16\n",
    "    \n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bilaplacian(p0,dx):   # En réalité bilaplacien modifié par les conditions aux bords\n",
    "        \n",
    "    p = impose_bc(p0,dx)\n",
    "    \n",
    "    N = p.shape[0]\n",
    "    Ap = numpy.zeros((N,N))\n",
    "    \n",
    "    Ap[2:-2,2:-2] = 20*p[2:-2,2:-2]-8*(p[1:-3,2:-2]+p[2:-2,1:-3]+p[2:-2,3:-1]+p[3:-1,2:-2])+\\\n",
    "                    2*(p[1:-3,1:-3]+p[1:-3,3:-1]+p[3:-1,1:-3]+p[3:-1,3:-1])+\\\n",
    "                    1*(p[:-4,2:-2]+p[2:-2,:-4]+p[2:-2,4:]+p[4:,2:-2])\n",
    "   \n",
    "    return Ap/dx**4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous récupérons et adaptons le code du mooc à notre problème."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conjugate_gradient_2d(p, b, dx, l1_target):\n",
    "    '''Performs cg relaxation\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    p : 2D array of floats\n",
    "        Initial guess\n",
    "    b : 2D array of floats\n",
    "        Source term\n",
    "    dx: float\n",
    "        Mesh spacing (same in both directions)\n",
    "    l1_target: float\n",
    "        exit criterion\n",
    "        \n",
    "    Returns:\n",
    "    -------\n",
    "    p: 2D array of float\n",
    "        Distribution after relaxation\n",
    "    '''\n",
    "    N = p.shape[0]\n",
    "    r  = numpy.zeros((N,N)) # residual\n",
    "    Ad  = numpy.zeros((N,N)) # to store result of matrix multiplication \n",
    "    \n",
    "    l1_norm = 1\n",
    "    iterations = 0\n",
    "    l1_conv = []\n",
    "    \n",
    "    # Step-0 We compute the initial residual and \n",
    "    # the first search direction is just this residual\n",
    "    \n",
    "    r = (b-bilaplacian(p,dx))\n",
    "    d = r.copy()\n",
    "    rho = numpy.sum(r*r)\n",
    "    Ad = bilaplacian(d,dx)\n",
    "    sigma = numpy.sum(d*Ad)\n",
    "    \n",
    "    # Iterations\n",
    "    while l1_norm > l1_target:\n",
    "\n",
    "        pk = p.copy()\n",
    "        rk = r.copy()\n",
    "        dk = d.copy()\n",
    "        \n",
    "        alpha = rho/sigma\n",
    "\n",
    "        p = pk + alpha*dk\n",
    "        r = rk - alpha*Ad\n",
    "        \n",
    "        rhop1 = numpy.sum(r*r)\n",
    "        beta = rhop1 / rho\n",
    "        rho = rhop1\n",
    "        \n",
    "        d = r + beta*dk\n",
    "        Ad = bilaplacian(d,dx)\n",
    "        sigma = numpy.sum(d*Ad)\n",
    "    \n",
    "        l1_norm = cg.L1norm(pk,p)\n",
    "        iterations += 1\n",
    "        l1_conv.append(l1_norm)\n",
    "    \n",
    "    print('Number of CG iterations: {0:d}'.format(iterations))\n",
    "    return p, l1_conv   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcul de la stream function qui respecte $\\Delta^2\\psi=0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous utilisons les paramètres (taille de grille, dimensions spatiales, précision désirée) imposées dans l'énoncé. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paramètres\n",
    "N = 41\n",
    "L = 1\n",
    "l1_target = 1e-8\n",
    "\n",
    "dx = L/(N-1)\n",
    "\n",
    "# initialisation -> on peut choisir ce qu'on veut\n",
    "p0 = numpy.ones((N,N))\n",
    "p0 = impose_bc(p0,dx)\n",
    "\n",
    "# résolution par gradient conjugué sur le centre (N-4)x(N-4) et écrit les valeurs au bord encore sur la réponse finale\n",
    "p, l1_conv = conjugate_gradient_2d(p0.copy(), 0, dx, l1_target)\n",
    "p = impose_bc(p,dx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\"> La méthode ne converge pas en moins de $nx\\times ny = 41\\times 41 = 1681$ itérations. Elle est très lente et le nombre d'itérations grandit rapidement avec l'inverse de la précision demandée. La méthode du gradient congugé ne semble pas fonctionner pour cet opérateur, probablement car celui-ci n'est pas symétrique. </font> <s> Nous remarquons que comme énoncé dans la théorie du mooc, la méthode a bien convergé en moins de $N=nx\\times ny = 41\\times 41 = 1681$ itérations.</s> La matrice semble prendre les valeurs attendues près des bords, comme nous pouvons le constater ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(p[-5:,:5])\n",
    "print(p[-5:,-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = numpy.linspace(0,L,N)\n",
    "y = numpy.linspace(0,L,N)\n",
    "\n",
    "pyplot.figure(figsize=(8,5))\n",
    "pyplot.contourf(x,y,p,100,cmap=cm.viridis)\n",
    "pyplot.xlabel('$x\\ [m]$')\n",
    "pyplot.ylabel('$y\\ [m]$')\n",
    "pyplot.colorbar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ap = bilaplacian(p,dx)\n",
    "\n",
    "x = numpy.linspace(0,L,N)\n",
    "y = numpy.linspace(0,L,N)\n",
    "\n",
    "pyplot.figure(figsize=(8,5))\n",
    "pyplot.contourf(x,y,Ap*dx**4,50,cmap=cm.viridis)\n",
    "pyplot.xlabel('$x\\ [m]$')\n",
    "pyplot.ylabel('$y\\ [m]$')\n",
    "pyplot.colorbar();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La méthode semble bien donner un bilaplacien assez proche de 0. <font color=\"red\"> Justif plus précise pour la comparaison </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Valeurs de la stream function aux positions demandées"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous commençons par définir une fonction nous permettant d'extraire la valeur de la stream function à partir des coordonnées cartésiennes. Nous extrayons ensuite les valeurs demandées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def p_at_coordinates(p,x,y):\n",
    "    \n",
    "    N = p.shape[0]\n",
    "    i = int(y*(N-1))\n",
    "    j = int(x*(N-1))\n",
    "    #print(\"coordinates i={:d} j={:d}\".format(i,j))\n",
    "    \n",
    "    return p[i,j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pij = p_at_coordinates(p,0.6,0.2)\n",
    "print(\"La valeur en x=0.6 et y=0.2 est:\",pij)\n",
    "\n",
    "pij = p_at_coordinates(p,0.6,0.4)\n",
    "print(\"La valeur en x=0.6 et y=0.4 est:\",pij)\n",
    "\n",
    "pij = p_at_coordinates(p,0.6,0.6)\n",
    "print(\"La valeur en x=0.6 et y=0.6 est:\",pij)\n",
    "\n",
    "pij = p_at_coordinates(p,0.6,0.8)\n",
    "print(\"La valeur en x=0.6 et y=0.8 est:\",pij)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_p = numpy.min(p)\n",
    "print(min_p)\n",
    "max_p = numpy.max(p)\n",
    "print(max_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Champ de vitesse du fluide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour mieux visualiser les mouvements de fluides apparaissant dans notre système, nous affichons le champ de vitesse à l'intérieur de la cavité."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = numpy.linspace(0,1,N-2)\n",
    "y = numpy.linspace(0,1,N-2)\n",
    "dy = dx\n",
    "vx = numpy.zeros((N-2,N-2))\n",
    "vy = numpy.zeros((N-2,N-2))\n",
    "\n",
    "vx =  1/2*(p[2:,1:-1] - p[0:-2,1:-1])/dy\n",
    "vy = -1/2*(p[1:-1,2:] - p[1:-1,0:-2])/dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.figure(figsize=(10,10))\n",
    "pyplot.quiver(x,y,vx,vy,color='b');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ordre de convergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous tenons à vérifier l'ordre de convergence de la méthode implémentée, qui devrait être du second ordre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nx_values = [11,21,31,41,61,81,121,161,241,321]\n",
    "l1_target = 1e-4\n",
    "L = 1\n",
    "\n",
    "dx = numpy.zeros(len(nx_values))\n",
    "for i in range(len(dx)):\n",
    "    dx[i] = L/(nx_values[i]-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = numpy.empty(len(nx_values)-1)\n",
    "p_centre = numpy.empty(len(nx_values))\n",
    "\n",
    "for i, nx in enumerate(nx_values):\n",
    "    \n",
    "    print(\"Currently at nx =\", nx_values[i])\n",
    "    p0 = numpy.zeros((nx,nx))\n",
    "    p, l1_conv = conjugate_gradient_2d(p0, 0, dx[i], l1_target)\n",
    "    p = impose_bc(p,dx[i])\n",
    "    p_centre[i] = p[int(nx/2),int(nx/2)]\n",
    "\n",
    "for i, nx in enumerate(nx_values[:-1]):\n",
    "    error[i] = numpy.abs(p_centre[i]-p_centre[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.figure(figsize=(6,6))\n",
    "pyplot.grid(True)\n",
    "pyplot.xlabel(r'$dx$', fontsize=18)\n",
    "pyplot.ylabel(r'$L_1$-norm of the error', fontsize=18)\n",
    "\n",
    "pyplot.loglog(dx[:-1], error, color='k', ls='--', lw=2, marker='o');\n",
    "pyplot.loglog(dx[:-1], dx[:-1]**2, color='r', ls='-', lw=2);\n",
    "pyplot.loglog(dx[:-1], dx[:-1], color='r', ls='-', lw=2);\n",
    "pyplot.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = numpy.empty(len(dx)-2)\n",
    "\n",
    "for i in range(len(alphas)):\n",
    "    \n",
    "    alphas[i] = (numpy.log(error[i+1])-numpy.log(error[i]))\\\n",
    "        /(numpy.log(dx[i+1])-numpy.log(dx[i]))\n",
    "    \n",
    "print(alphas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\"> La méthode est trop lente pour être correctement testée. </font>  <s> Nous remarquons que l'ordre de convergence de la méthode tourne autour de 1.5. Cette valeur est assez éloignée de l'ordre attendu qui vaut 2. N'ayant pas repéré d'erreur dans notre implémentation, nous ne comprenons pas pourquoi un tel écart existe entre l'ordre réel et l'ordre que la méthode est censée suivre. </s>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">  ** TODO **  </font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
